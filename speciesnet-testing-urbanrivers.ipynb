{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":348614,"sourceType":"modelInstanceVersion","modelInstanceId":291118,"modelId":247762}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Notebook Setup and Required Packages","metadata":{}},{"cell_type":"code","source":"# Data Handling\nimport pandas as pd\nimport numpy as np\n\n# IO - getting files and images from MongoDB and S3\nfrom pymongo import MongoClient\nfrom kaggle_secrets import UserSecretsClient\nimport requests\n\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom pathlib import Path\nfrom PIL import Image\nfrom io import BytesIO\n\nimport os\nimport re\nimport shutil\nimport json\nimport time\n\n# Install speciesnet and related megadetector libraries\n!pip install -Uqq speciesnet megadetector-utils\n\nfrom IPython.display import display\nfrom IPython.display import JSON\n\nfrom speciesnet import SpeciesNet\nimport kagglehub\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T14:46:00.614253Z","iopub.execute_input":"2025-05-19T14:46:00.614468Z","iopub.status.idle":"2025-05-19T14:48:09.841168Z","shell.execute_reply.started":"2025-05-19T14:46:00.614441Z","shell.execute_reply":"2025-05-19T14:48:09.840394Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.3/791.3 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m956.3/956.3 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for pyqtree (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for reverse_geocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.3 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Run a quick check to see if the GPU is being used\n!python -m speciesnet.scripts.gpu_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T14:48:09.843111Z","iopub.execute_input":"2025-05-19T14:48:09.843523Z","iopub.status.idle":"2025-05-19T14:48:21.927439Z","shell.execute_reply.started":"2025-05-19T14:48:09.843500Z","shell.execute_reply":"2025-05-19T14:48:21.926727Z"}},"outputs":[{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/usr/local/lib/python3.11/dist-packages/speciesnet/__init__.py\", line 19, in <module>\n    from speciesnet.detector import *\n  File \"/usr/local/lib/python3.11/dist-packages/speciesnet/detector.py\", line 31, in <module>\n    from yolov5.utils.augmentations import letterbox as yolov5_letterbox\n  File \"/usr/local/lib/python3.11/dist-packages/yolov5/__init__.py\", line 1, in <module>\n    from yolov5.helpers import YOLOv5\n  File \"/usr/local/lib/python3.11/dist-packages/yolov5/helpers.py\", line 4, in <module>\n    from yolov5.models.common import AutoShape, DetectMultiBackend\n  File \"/usr/local/lib/python3.11/dist-packages/yolov5/models/common.py\", line 18, in <module>\n    import cv2\n  File \"/usr/local/lib/python3.11/dist-packages/cv2/__init__.py\", line 181, in <module>\n    bootstrap()\n  File \"/usr/local/lib/python3.11/dist-packages/cv2/__init__.py\", line 153, in bootstrap\n    native_module = importlib.import_module(\"cv2\")\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Configuration for Multithreading and Batching\nnum_batches = 10\nmax_threads = 8\noutput_root = Path(\"output\")\n\n# Prepare folders\noutput_root.mkdir(exist_ok=True)\nimages_root = Path(\"images\")\nimages_root.mkdir(exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T14:48:50.420254Z","iopub.execute_input":"2025-05-19T14:48:50.420562Z","iopub.status.idle":"2025-05-19T14:48:50.466211Z","shell.execute_reply.started":"2025-05-19T14:48:50.420539Z","shell.execute_reply":"2025-05-19T14:48:50.447164Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Access The URIs from S3 through MongoDB","metadata":{}},{"cell_type":"code","source":"# Get the stored mongo uri secret\nuser_secrets = UserSecretsClient()\nmongo_uri = user_secrets.get_secret(\"MONGO_URI\")\n\n# Connect to the MongoDB client\nclient = MongoClient(mongo_uri)\n \n# Access the database and collection\ndb = client['test']\ncollection = db['cameratrapmedias'] \n \n# Query the collection to retrieve records with image URLs, metadata, and the first index of 'relativePath'\ndata = list(collection.aggregate([\n    {\n        '$project': {\n            '_id': 0,\n            'publicURL': 1,\n            'timestamp': 1,\n            'folderName': { '$arrayElemAt': ['$relativePath', 1] },\n            'fileName': 1\n        }\n    },\n    # { '$limit': 150 }\n]))\n \n# Convert the data to a pandas DataFrame for exploration\ndf = pd.DataFrame(data)\n\n# Export the small array to a CSV file for preview\ndf.to_csv('ur_test_medias.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2025-05-19T14:48:52.432852Z","iopub.execute_input":"2025-05-19T14:48:52.433402Z","iopub.status.idle":"2025-05-19T14:48:56.800981Z","shell.execute_reply.started":"2025-05-19T14:48:52.433375Z","shell.execute_reply":"2025-05-19T14:48:56.800191Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## We are going to create a column that creates a file name to save the image","metadata":{}},{"cell_type":"code","source":"# This function will format the final string\ndef make_filename(s):\n    # s = s.lower()\n    s = re.sub(r'[^\\w\\s.-]', '', s) # remove special characters except dash or underscore or period\n    s = re.sub(r'\\s+', '_', s) # replace whitespace with underscore\n    return s\n\n# Combine the relative path second (folder name) + fileName\ndf['imageName'] = df['folderName'] + '--' + df['fileName']\ndf['imageName'] = df['imageName'].apply(make_filename)\n\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T14:48:59.343934Z","iopub.execute_input":"2025-05-19T14:48:59.351917Z","iopub.status.idle":"2025-05-19T14:48:59.784579Z","shell.execute_reply.started":"2025-05-19T14:48:59.351876Z","shell.execute_reply":"2025-05-19T14:48:59.772818Z"}},"outputs":[{"name":"stdout","text":"            timestamp                                          publicURL  \\\n0 2024-01-27 13:33:15  https://urbanriverrangers.s3.amazonaws.com/ima...   \n1 2024-01-24 18:56:50  https://urbanriverrangers.s3.amazonaws.com/ima...   \n2 2024-01-24 19:01:54  https://urbanriverrangers.s3.amazonaws.com/ima...   \n3 2024-01-24 19:03:05  https://urbanriverrangers.s3.amazonaws.com/ima...   \n4 2024-01-24 19:04:19  https://urbanriverrangers.s3.amazonaws.com/ima...   \n\n       fileName                               folderName  \\\n0  SYFW0060.JPG                   2024-01-30_prologis_02   \n1  SYFW0001.JPG  2024-01-30_Learnin_platform_camera_test   \n2  SYFW0002.JPG  2024-01-30_Learnin_platform_camera_test   \n3  SYFW0004.JPG  2024-01-30_Learnin_platform_camera_test   \n4  SYFW0006.JPG  2024-01-30_Learnin_platform_camera_test   \n\n                                           imageName  \n0               2024-01-30_prologis_02--SYFW0060.JPG  \n1  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n2  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n3  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n4  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Now that we have a connection to the MongoDB server and access to the URLs, let's use the download images.","metadata":{}},{"cell_type":"markdown","source":"## Download Images","metadata":{}},{"cell_type":"code","source":"%%time\n# Create a directory to save the images\noutput_root.mkdir(exist_ok=True)\npath = Path('images')\npath.mkdir(exist_ok=True)\n\n# Create a tool for resizing so cropping top and bottom can happen while keeping the aspect ratio\ndef resize_to_height(image, target_height=256):\n    og_width, og_height = image.size\n    new_width = int(og_width * (target_height / og_height))\n    return image.resize((new_width, target_height))\n\n# Create a tool for downloading and processing images\ndef process_row(row, dest_folder):\n    url = row['publicURL']\n    filename = row['imageName']\n    # Download the image\n    dest = dest_folder/filename\n\n    try:\n        # Download image to memory\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Open and process the image\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n        image = resize_to_height(image, target_height=256)\n        image.save(dest, format=\"JPEG\", quality=85)\n        \n    except Exception as e:\n        print(f\"failed to process{filename}: {e}\")\n\n# Download and display some images where at least an animal was found - ex rat\ndf_test = df[44410:44910] # 500 images with some known animal detections\ndf_big_chunk = df[0:10000] # first 10000 images\n\n# Process Batches\nfor batch_idx, df_chunk in enumerate(np.array_split(df_big_chunk, num_batches)): # change to df_test to split a test batch size\n    batch_folder = images_root / f'batch_{batch_idx}'\n    batch_folder.mkdir(exist_ok=True)\n\n    print(f'Processing batch {batch_idx + 1} / {num_batches} with {len(df_chunk)} images...')\n\n    start = time.time()\n    \n    with ThreadPoolExecutor(max_workers=max_threads) as executor:\n        executor.map(lambda row: process_row(row, batch_folder), [row for _, row in df_chunk.iterrows()])\n\n    end = time.time()\n    print(f\"Batch {batch_idx+1} took {end - start:.2f} seconds.\")\n        \nprint(f'{len(df_big_chunk)} Images Downloaded and Resized')","metadata":{"execution":{"iopub.status.busy":"2025-05-19T15:09:54.533166Z","iopub.execute_input":"2025-05-19T15:09:54.534095Z","iopub.status.idle":"2025-05-19T15:28:43.797571Z","shell.execute_reply.started":"2025-05-19T15:09:54.534068Z","shell.execute_reply":"2025-05-19T15:28:43.796930Z"},"trusted":true,"_kg_hide-output":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 1 / 10 with 1000 images...\nBatch 1 took 242.91 seconds.\nProcessing batch 2 / 10 with 1000 images...\nBatch 2 took 130.37 seconds.\nProcessing batch 3 / 10 with 1000 images...\nBatch 3 took 213.68 seconds.\nProcessing batch 4 / 10 with 1000 images...\nBatch 4 took 71.11 seconds.\nProcessing batch 5 / 10 with 1000 images...\nBatch 5 took 73.70 seconds.\nProcessing batch 6 / 10 with 1000 images...\nBatch 6 took 86.57 seconds.\nProcessing batch 7 / 10 with 1000 images...\nBatch 7 took 77.40 seconds.\nProcessing batch 8 / 10 with 1000 images...\nBatch 8 took 79.47 seconds.\nProcessing batch 9 / 10 with 1000 images...\nBatch 9 took 77.65 seconds.\nProcessing batch 10 / 10 with 1000 images...\nBatch 10 took 76.38 seconds.\n10000 Images Downloaded and Resized\nCPU times: user 47min, sys: 3min 19s, total: 50min 20s\nWall time: 18min 49s\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Uncomment and run this if the images need to be redone\n# !rm images -r\n# !rm docs.zip\n# %lsmagic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:28:43.798732Z","iopub.execute_input":"2025-05-19T15:28:43.798935Z","iopub.status.idle":"2025-05-19T15:28:43.802376Z","shell.execute_reply.started":"2025-05-19T15:28:43.798919Z","shell.execute_reply":"2025-05-19T15:28:43.801632Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Running Species Net on the Full Dataset\nNow that we have the max number of images downloaded (19.5GB) let's run speciesnet\n\nNote there might be a better way of doing this using bytes downloaded from s3 - but I haven't figured that part out yet.\n\n### We're going to try a multithreading chunks approach","metadata":{}},{"cell_type":"code","source":"def print_predictions(predictions_dict: dict) -> None:\n    print(\"Predictions:\")\n    for prediction in predictions_dict[\"predictions\"][0:1]:\n        print(prediction[\"filepath\"], \"=>\", prediction[\"prediction\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:28:43.802888Z","iopub.execute_input":"2025-05-19T15:28:43.803065Z","iopub.status.idle":"2025-05-19T15:28:43.821867Z","shell.execute_reply.started":"2025-05-19T15:28:43.803051Z","shell.execute_reply":"2025-05-19T15:28:43.821184Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"### Download Model","metadata":{}},{"cell_type":"code","source":"# Choose the folder we're going to download the model to\nmodel_path = '/content/models'\nos.makedirs(model_path, exist_ok=True)\n\n# Download the model (it will go to a folder like /kaggle/input/...)\ndownload_path = kagglehub.model_download('google/speciesnet/PyTorch/v4.0.1a',\n                                          force_download=True)\n\nprint('Model downloaded to temporary folder: {}'.format(download_path))\n\n# List the contents of the downloaded directory to identify the actual files/subdirectories\nmodel_files = os.listdir(download_path)\n\n# Copy the contents of the model file to our destination folder\nfor item_name in model_files:\n    source_path = os.path.join(download_path, item_name)\n    destination_path = os.path.join(model_path, item_name)\n    if os.path.isfile(source_path):\n        shutil.copy2(source_path, destination_path)\n    elif os.path.isdir(source_path):\n        shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n\nprint('{} files copied to: {}'.format(len(model_files),model_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:28:43.822493Z","iopub.execute_input":"2025-05-19T15:28:43.822678Z","iopub.status.idle":"2025-05-19T15:28:44.720092Z","shell.execute_reply.started":"2025-05-19T15:28:43.822665Z","shell.execute_reply":"2025-05-19T15:28:44.719487Z"}},"outputs":[{"name":"stdout","text":"Model downloaded to temporary folder: /kaggle/input/speciesnet/pytorch/v4.0.1a/1\n6 files copied to: /content/models\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Pick the model we want to use (4.0.1a)\nmodel = SpeciesNet(model_path)\n\nprint('Model Loaded')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:28:44.721588Z","iopub.execute_input":"2025-05-19T15:28:44.721800Z","iopub.status.idle":"2025-05-19T15:28:46.254065Z","shell.execute_reply.started":"2025-05-19T15:28:44.721783Z","shell.execute_reply":"2025-05-19T15:28:46.253484Z"}},"outputs":[{"name":"stdout","text":"Model Loaded\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Let's format a request string as a list of dicts (aka JSON string format)\ndef create_instances(batch_folder):\n    image_paths = [f'{batch_folder}/{f}' for f in os.listdir(batch_folder) if f.lower().endswith('.jpg')]\n\n    instances = []\n    for image_path in image_paths:\n        instances.append({\n            'filepath': image_path,\n            'latitude': 41.906782,\n            'longitude': -87.651927\n        })\n\n    # Check that it's saved correctly by verifying the first\n    print(instances[0])\n\n    return instances\n\n\nfor batch_index in range(len(os.listdir(images_root))):\n    instances = create_instances(f'{images_root}/batch_{batch_index}')\n\n    # make the predictions and get a sense of how long it would take\n    %time predictions_dict = model.predict(instances_dict={\"instances\": instances})\n\n    print_predictions(predictions_dict) # show the first prediction of each batch\n\n    # Save the dict to the batch folder\n    with open(f'{images_root}/batch_{batch_index}/predictions_dict_{batch_index}.json', 'w') as f:\n        json.dump(predictions_dict, f, indent=2)\n\n    print(f'predictions_dict_{batch_index}.json saved to {images_root}/batch_{batch_index}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:28:46.254732Z","iopub.execute_input":"2025-05-19T15:28:46.254920Z","iopub.status.idle":"2025-05-19T15:47:38.323544Z","shell.execute_reply.started":"2025-05-19T15:28:46.254898Z","shell.execute_reply":"2025-05-19T15:47:38.322764Z"}},"outputs":[{"name":"stdout","text":"{'filepath': 'images/batch_0/2024-02-01_16-41-42--SYEW0373.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 4min 1s, sys: 2.28 s, total: 4min 3s\nWall time: 1min 58s\nPredictions:\nimages/batch_0/2024-02-01_16-41-42--SYEW0373.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_0.json saved to images/batch_0\n{'filepath': 'images/batch_1/2024-02-01_16-41-42--SYEW1833.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 4min 22s, sys: 2.14 s, total: 4min 24s\nWall time: 2min 8s\nPredictions:\nimages/batch_1/2024-02-01_16-41-42--SYEW1833.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_1.json saved to images/batch_1\n{'filepath': 'images/batch_2/2024-02-01_Bubbly_spypoint_garden--HDPH0058.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 38s, sys: 2.29 s, total: 3min 41s\nWall time: 1min 47s\nPredictions:\nimages/batch_2/2024-02-01_Bubbly_spypoint_garden--HDPH0058.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_2.json saved to images/batch_2\n{'filepath': 'images/batch_3/2024-02-01_Bubbly_spypoint_garden--HDPH1028.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 38s, sys: 1.51 s, total: 3min 39s\nWall time: 1min 47s\nPredictions:\nimages/batch_3/2024-02-01_Bubbly_spypoint_garden--HDPH1028.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_3.json saved to images/batch_3\n{'filepath': 'images/batch_4/2024-02-01_Bubbly_spypoint_garden--HDPH2548.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 41s, sys: 1.65 s, total: 3min 43s\nWall time: 1min 48s\nPredictions:\nimages/batch_4/2024-02-01_Bubbly_spypoint_garden--HDPH2548.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_4.json saved to images/batch_4\n{'filepath': 'images/batch_5/2024-02-01_16-41-42--SYEW0373.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 42s, sys: 3.3 s, total: 3min 45s\nWall time: 1min 49s\nPredictions:\nimages/batch_5/2024-02-01_16-41-42--SYEW0373.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_5.json saved to images/batch_5\n{'filepath': 'images/batch_6/2024-02-01_Bubbly_spypoint_garden--HDPH4115.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 41s, sys: 1.86 s, total: 3min 42s\nWall time: 1min 48s\nPredictions:\nimages/batch_6/2024-02-01_Bubbly_spypoint_garden--HDPH4115.JPG => f2efdae9-efb8-48fb-8a91-eccf79ab4ffb;no cv result;no cv result;no cv result;no cv result;no cv result;no cv result\npredictions_dict_6.json saved to images/batch_6\n{'filepath': 'images/batch_7/2024-02-01_Bubbly_spypoint_garden--HDPH5442.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 40s, sys: 1.4 s, total: 3min 41s\nWall time: 1min 48s\nPredictions:\nimages/batch_7/2024-02-01_Bubbly_spypoint_garden--HDPH5442.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_7.json saved to images/batch_7\n{'filepath': 'images/batch_8/2024-02-01_Bubbly_spypoint_garden--HDPH6050.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 3min 41s, sys: 1.66 s, total: 3min 42s\nWall time: 1min 48s\nPredictions:\nimages/batch_8/2024-02-01_Bubbly_spypoint_garden--HDPH6050.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_8.json saved to images/batch_8\n{'filepath': 'images/batch_9/2024-02-01_Bubbly_spypoint_garden--HDPH7235.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\nCPU times: user 4min 16s, sys: 2.8 s, total: 4min 19s\nWall time: 2min 6s\nPredictions:\nimages/batch_9/2024-02-01_Bubbly_spypoint_garden--HDPH7235.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\npredictions_dict_9.json saved to images/batch_9\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# To concatenate all the json files\noutput_file = output_root / \"predictions_dict_master.json\"\n\n# Initialize the master predictions list\nmaster_predictions = []\n\n# Loop through files matching the pattern\nfor json_file in sorted(images_root.glob(\"batch_*/predictions_dict_*.json\")):\n    with open(json_file, \"r\") as f:\n        data = json.load(f)\n        if \"predictions\" in data:\n            master_predictions.extend(data[\"predictions\"])  # Concatenate predictions!\n        else:\n            print(f\"{json_file} missing 'predictions' key\")\n\n# Write the combined predictions to a new file\nwith open(output_file, \"w\") as f:\n    json.dump({\"predictions\": master_predictions}, f, indent=2)\n\nprint(f\"Combined {len(master_predictions)} predictions into {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:47:38.324497Z","iopub.execute_input":"2025-05-19T15:47:38.325267Z","iopub.status.idle":"2025-05-19T15:47:39.581066Z","shell.execute_reply.started":"2025-05-19T15:47:38.325244Z","shell.execute_reply":"2025-05-19T15:47:39.580373Z"}},"outputs":[{"name":"stdout","text":"Combined 11128 predictions into output/predictions_dict_master.json\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Let's save the predictions dict json file","metadata":{}},{"cell_type":"code","source":"# Create a docs folder for previewing the images\noutput_path = '/kaggle/working/output/docs'\nos.makedirs(output_path, exist_ok=True)\n\n!python -m megadetector.postprocessing.postprocess_batch_results /kaggle/working/output/predictions_dict_master.json /kaggle/working/output/docs --num_images_to_sample -1 --confidence_threshold 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:29:11.392225Z","iopub.execute_input":"2025-05-19T16:29:11.392814Z"}},"outputs":[{"name":"stdout","text":"Loading results from /kaggle/working/output/predictions_dict_master.json\nThis appears to be a SpeciesNet output file, converting to MD format\nWriting temporary results to /tmp/megadetector_temp_files/663ee936-34ce-11f0-b1bd-0242ac130202.json\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nWarning: creating fake detection for non-blank whole-image classification\nConverting results to dataframe\nFinished loading MegaDetector results for 11128 images from /kaggle/working/output/predictions_dict_master.json\nAssigning images to rendering categories\n100%|██████████████████████████████████| 11128/11128 [00:00<00:00, 27840.67it/s]\nFinished loading and preprocessing 11128 rows from detector output, predicted 499 positives.\n 43%|████████████████▍                     | 4802/11128 [00:55<01:06, 94.68it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Let's zip the folder so we can easily download it","metadata":{}},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/output/docs', 'zip', '/kaggle/working/output/docs')\n\n# and finally clean up the tree that made it this far\nshutil.rmtree('/kaggle/working/output/docs')  # Deletes the folder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:47:50.136837Z","iopub.execute_input":"2025-05-19T15:47:50.137516Z","iopub.status.idle":"2025-05-19T15:47:51.491938Z","shell.execute_reply.started":"2025-05-19T15:47:50.137490Z","shell.execute_reply":"2025-05-19T15:47:51.491119Z"}},"outputs":[],"execution_count":31}]}
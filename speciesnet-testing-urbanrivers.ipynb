{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0807486f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Urban Rivers is a conservation organization helping to restore the Chicago River.  \n",
    "\n",
    "Part of the project involves tracking changes in biodiversity attributable to the installation of floating wetlands.  \n",
    "Volunteers have placed and maintain motion detection cameras (camera traps) along installations, natural river banks, and the existing metal retaining walls on the water way.\n",
    "\n",
    "These pictures are available on s3 - this code investigates downloading a portion of those images for testing with SpeciesNet.\n",
    "\n",
    "This workbook was used for detections using Kaggle's GPUs and is linked therein.  \n",
    "https://www.kaggle.com/code/morescope/speciesnet-testing-urbanrivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8f6e2",
   "metadata": {
    "papermill": {
     "duration": 0.003793,
     "end_time": "2025-05-19T19:22:53.568317",
     "exception": false,
     "start_time": "2025-05-19T19:22:53.564524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook Setup and Required Packages\n",
    "\n",
    "Before importing packages below, retrieve your Kaggle API key following [these steps](https://www.kaggle.com/discussions/questions-and-answers/357399#2880045).  You should end up downloading a `kaggle.json` file, whose content will look like this:\n",
    "\n",
    "`{\"username\":\"your-kaggle-id\",\"key\":\"your-kaggle-API-key\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6178647d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T19:22:53.575483Z",
     "iopub.status.busy": "2025-05-19T19:22:53.575275Z",
     "iopub.status.idle": "2025-05-19T19:25:18.249349Z",
     "shell.execute_reply": "2025-05-19T19:25:18.248520Z"
    },
    "papermill": {
     "duration": 144.679305,
     "end_time": "2025-05-19T19:25:18.250983",
     "exception": false,
     "start_time": "2025-05-19T19:22:53.571678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# IO - getting files and images from MongoDB and S3\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# # https://www.kaggle.com/discussions/questions-and-answers/357399\n",
    "# # NOTE - Uncomment next two lines if `kaggle_secrets` throws errors\n",
    "# import sys\n",
    "# sys.path.append(\"docker-python/patches\")\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "import requests\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Install speciesnet and related megadetector libraries\n",
    "!pip install -Uqq speciesnet megadetector-utils\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import JSON\n",
    "\n",
    "from speciesnet import SpeciesNet\n",
    "import kagglehub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "535bbf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T19:25:18.303062Z",
     "iopub.status.busy": "2025-05-19T19:25:18.302085Z",
     "iopub.status.idle": "2025-05-19T19:25:34.171317Z",
     "shell.execute_reply": "2025-05-19T19:25:34.170550Z"
    },
    "papermill": {
     "duration": 15.896389,
     "end_time": "2025-05-19T19:25:34.172882",
     "exception": false,
     "start_time": "2025-05-19T19:25:18.276493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Running Torch tests ***\n",
      "\n",
      "Torch version: 2.6.0\n",
      "CUDA available (according to PyTorch): False\n",
      "No GPUs reported by PyTorch\n",
      "PyTorch reports that Metal Performance Shaders are available\n"
     ]
    }
   ],
   "source": [
    "# Run a quick check to see if the GPU is being used\n",
    "# !pip install chardet  # NOTE - try this if next line throws a warning\n",
    "!python -m speciesnet.scripts.gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f599d222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T19:25:34.224134Z",
     "iopub.status.busy": "2025-05-19T19:25:34.223866Z",
     "iopub.status.idle": "2025-05-19T19:25:34.228769Z",
     "shell.execute_reply": "2025-05-19T19:25:34.228217Z"
    },
    "papermill": {
     "duration": 0.031322,
     "end_time": "2025-05-19T19:25:34.229885",
     "exception": false,
     "start_time": "2025-05-19T19:25:34.198563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration for Multithreading and Batching\n",
    "num_batches = 10\n",
    "max_threads = 8\n",
    "output_root = Path(\"output\")\n",
    "\n",
    "# Prepare folders\n",
    "output_root.mkdir(exist_ok=True)\n",
    "images_root = Path(\"images\")\n",
    "images_root.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a4ea9",
   "metadata": {
    "papermill": {
     "duration": 0.024318,
     "end_time": "2025-05-19T19:25:34.279312",
     "exception": false,
     "start_time": "2025-05-19T19:25:34.254994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Access The URIs from S3 through MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee399a95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T19:25:34.329089Z",
     "iopub.status.busy": "2025-05-19T19:25:34.328898Z",
     "iopub.status.idle": "2025-05-19T19:25:40.997842Z",
     "shell.execute_reply": "2025-05-19T19:25:40.996970Z"
    },
    "papermill": {
     "duration": 6.695545,
     "end_time": "2025-05-19T19:25:40.999302",
     "exception": false,
     "start_time": "2025-05-19T19:25:34.303757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the stored mongo uri secret - and if not using Kaggle, should be able to use `os.getenv()`\n",
    "# user_secrets = UserSecretsClient()\n",
    "# mongo_uri = user_secrets.get_secret(\"MONGO_URI\")\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "# Connect to the MongoDB client\n",
    "client = MongoClient(mongo_uri)\n",
    " \n",
    "# Access the database and collection\n",
    "db = client['test']\n",
    "collection = db['cameratrapmedias'] \n",
    " \n",
    "# Query the collection to retrieve records with image URLs, metadata, and the first index of 'relativePath'\n",
    "data = list(collection.aggregate([\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'publicURL': 1,\n",
    "            'timestamp': 1,\n",
    "            'folderName': { '$arrayElemAt': ['$relativePath', 1] },\n",
    "            'fileName': 1\n",
    "        }\n",
    "    },\n",
    "    # { '$limit': 150 }\n",
    "]))\n",
    " \n",
    "# Convert the data to a pandas DataFrame for exploration\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Export the small array to a CSV file for preview\n",
    "df.to_csv('ur_test_medias.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2665bfc",
   "metadata": {
    "papermill": {
     "duration": 0.026293,
     "end_time": "2025-05-19T19:25:41.051777",
     "exception": false,
     "start_time": "2025-05-19T19:25:41.025484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We are going to create a column that creates a file name to save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66ce5560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T19:25:41.150783Z",
     "iopub.status.busy": "2025-05-19T19:25:41.150432Z",
     "iopub.status.idle": "2025-05-19T19:25:41.435978Z",
     "shell.execute_reply": "2025-05-19T19:25:41.434898Z"
    },
    "papermill": {
     "duration": 0.31235,
     "end_time": "2025-05-19T19:25:41.437249",
     "exception": false,
     "start_time": "2025-05-19T19:25:41.124899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp                                          publicURL  \\\n",
      "0 2024-01-27 13:33:15  https://urbanriverrangers.s3.amazonaws.com/ima...   \n",
      "1 2024-01-24 18:56:50  https://urbanriverrangers.s3.amazonaws.com/ima...   \n",
      "2 2024-01-24 19:01:54  https://urbanriverrangers.s3.amazonaws.com/ima...   \n",
      "3 2024-01-24 19:03:05  https://urbanriverrangers.s3.amazonaws.com/ima...   \n",
      "4 2024-01-24 19:04:19  https://urbanriverrangers.s3.amazonaws.com/ima...   \n",
      "\n",
      "       fileName                               folderName  \\\n",
      "0  SYFW0060.JPG                   2024-01-30_prologis_02   \n",
      "1  SYFW0001.JPG  2024-01-30_Learnin_platform_camera_test   \n",
      "2  SYFW0002.JPG  2024-01-30_Learnin_platform_camera_test   \n",
      "3  SYFW0004.JPG  2024-01-30_Learnin_platform_camera_test   \n",
      "4  SYFW0006.JPG  2024-01-30_Learnin_platform_camera_test   \n",
      "\n",
      "                                           imageName  \n",
      "0               2024-01-30_prologis_02--SYFW0060.JPG  \n",
      "1  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n",
      "2  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n",
      "3  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n",
      "4  2024-01-30_Learnin_platform_camera_test--SYFW0...  \n"
     ]
    }
   ],
   "source": [
    "# This function will format the final string\n",
    "def make_filename(s):\n",
    "    # s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s.-]', '', s) # remove special characters except dash or underscore or period\n",
    "    s = re.sub(r'\\s+', '_', s) # replace whitespace with underscore\n",
    "    return s\n",
    "\n",
    "# Combine the relative path second (folder name) + fileName\n",
    "df['imageName'] = df['folderName'] + '--' + df['fileName']\n",
    "df['imageName'] = df['imageName'].apply(make_filename)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e6922",
   "metadata": {
    "papermill": {
     "duration": 0.024795,
     "end_time": "2025-05-19T19:25:41.487544",
     "exception": false,
     "start_time": "2025-05-19T19:25:41.462749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have a connection to the MongoDB server and access to the URLs, let's use the download images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e2400",
   "metadata": {
    "papermill": {
     "duration": 0.024287,
     "end_time": "2025-05-19T19:25:41.537050",
     "exception": false,
     "start_time": "2025-05-19T19:25:41.512763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38e96d32",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-19T19:25:41.588516Z",
     "iopub.status.busy": "2025-05-19T19:25:41.588228Z",
     "iopub.status.idle": "2025-05-19T22:32:03.320395Z",
     "shell.execute_reply": "2025-05-19T22:32:03.319644Z"
    },
    "papermill": {
     "duration": 11181.78668,
     "end_time": "2025-05-19T22:32:03.348811",
     "exception": false,
     "start_time": "2025-05-19T19:25:41.562131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kaggle/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 / 10 with 50 images...\n",
      "Batch 1 took 2.26 seconds.\n",
      "Processing batch 2 / 10 with 50 images...\n",
      "Batch 2 took 2.38 seconds.\n",
      "Processing batch 3 / 10 with 50 images...\n",
      "Batch 3 took 2.31 seconds.\n",
      "Processing batch 4 / 10 with 50 images...\n",
      "Batch 4 took 2.43 seconds.\n",
      "Processing batch 5 / 10 with 50 images...\n",
      "Batch 5 took 2.37 seconds.\n",
      "Processing batch 6 / 10 with 50 images...\n",
      "Batch 6 took 2.54 seconds.\n",
      "Processing batch 7 / 10 with 50 images...\n",
      "Batch 7 took 2.39 seconds.\n",
      "Processing batch 8 / 10 with 50 images...\n",
      "Batch 8 took 2.29 seconds.\n",
      "Processing batch 9 / 10 with 50 images...\n",
      "Batch 9 took 2.04 seconds.\n",
      "Processing batch 10 / 10 with 50 images...\n",
      "Batch 10 took 2.02 seconds.\n",
      "500 Images Downloaded and Resized\n",
      "CPU times: user 22.4 s, sys: 4.22 s, total: 26.6 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a directory to save the images\n",
    "output_root.mkdir(exist_ok=True)\n",
    "path = Path('images')\n",
    "path.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a tool for resizing so cropping top and bottom can happen while keeping the aspect ratio\n",
    "def resize_to_height(image, target_height=256):\n",
    "    og_width, og_height = image.size\n",
    "    new_width = int(og_width * (target_height / og_height))\n",
    "    return image.resize((new_width, target_height))\n",
    "\n",
    "# Create a tool for downloading and processing images\n",
    "def process_row(row, dest_folder):\n",
    "    url = row['publicURL']\n",
    "    filename = row['imageName']\n",
    "    # Download the image\n",
    "    dest = dest_folder/filename\n",
    "\n",
    "    try:\n",
    "        # Download image to memory\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Open and process the image\n",
    "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        image = resize_to_height(image, target_height=256)\n",
    "        image.save(dest, format=\"JPEG\", quality=85)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"failed to process{filename}: {e}\")\n",
    "\n",
    "# Download and display some images where at least an animal was found - ex rat\n",
    "df_test = df[42410:42910] # 500 images with some known animal detections\n",
    "df_big_chunk = df[0:10000] # first 10000 images\n",
    "df_bigger_chunk = df[10001:60001] # second 50k\n",
    "\n",
    "# Process Batches\n",
    "for batch_idx, df_chunk in enumerate(np.array_split(df_test, num_batches)): # change to df_bigger_chunk to split a larger batch size\n",
    "    batch_folder = images_root / f'batch_{batch_idx}'\n",
    "    batch_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f'Processing batch {batch_idx + 1} / {num_batches} with {len(df_chunk)} images...')\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        executor.map(lambda row: process_row(row, batch_folder), [row for _, row in df_chunk.iterrows()])\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Batch {batch_idx+1} took {end - start:.2f} seconds.\")\n",
    "        \n",
    "print(f'{len(df_test)} Images Downloaded and Resized')  # ... df_bigger_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffc75eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T22:32:03.400969Z",
     "iopub.status.busy": "2025-05-19T22:32:03.400452Z",
     "iopub.status.idle": "2025-05-19T22:32:03.403831Z",
     "shell.execute_reply": "2025-05-19T22:32:03.403143Z"
    },
    "papermill": {
     "duration": 0.030683,
     "end_time": "2025-05-19T22:32:03.404889",
     "exception": false,
     "start_time": "2025-05-19T22:32:03.374206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this if the images need to be redone\n",
    "# !rm images -r\n",
    "# !rm docs.zip\n",
    "# %lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b8bbd",
   "metadata": {
    "papermill": {
     "duration": 0.025167,
     "end_time": "2025-05-19T22:32:03.455574",
     "exception": false,
     "start_time": "2025-05-19T22:32:03.430407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running Species Net on the Full Dataset\n",
    "Now that we have the max number of images downloaded (19.5GB) let's run speciesnet\n",
    "\n",
    "Note there might be a better way of doing this using bytes downloaded from s3 - but I haven't figured that part out yet.\n",
    "\n",
    "### We're going to try a multithreading chunks approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b0fe915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T22:32:03.508054Z",
     "iopub.status.busy": "2025-05-19T22:32:03.507455Z",
     "iopub.status.idle": "2025-05-19T22:32:03.511535Z",
     "shell.execute_reply": "2025-05-19T22:32:03.510849Z"
    },
    "papermill": {
     "duration": 0.031176,
     "end_time": "2025-05-19T22:32:03.512560",
     "exception": false,
     "start_time": "2025-05-19T22:32:03.481384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_predictions(predictions_dict: dict) -> None:\n",
    "    print(\"Predictions:\")\n",
    "    for prediction in predictions_dict[\"predictions\"][0:1]:\n",
    "        print(prediction[\"filepath\"], \"=>\", prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d03be",
   "metadata": {
    "papermill": {
     "duration": 0.026931,
     "end_time": "2025-05-19T22:32:03.565120",
     "exception": false,
     "start_time": "2025-05-19T22:32:03.538189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da35dda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T22:32:03.616353Z",
     "iopub.status.busy": "2025-05-19T22:32:03.615965Z",
     "iopub.status.idle": "2025-05-19T22:32:07.943774Z",
     "shell.execute_reply": "2025-05-19T22:32:07.943012Z"
    },
    "papermill": {
     "duration": 4.354498,
     "end_time": "2025-05-19T22:32:07.944914",
     "exception": false,
     "start_time": "2025-05-19T22:32:03.590416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205a0961fa9d43d4808e7df615ae4682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/always_crop_99710272_22x8_v12_epoch_00148.labels.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/README.md...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/taxonomy_release.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "100%|██████████| 119/119 [00:00<00:00, 55.0kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/geofence_release.2025.02.27.0702.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/info.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 399/399 [00:00<00:00, 719kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/google/speciesnet/PyTorch/v4.0.1a/1/download/always_crop_99710272_22x8_v12_epoch_00148.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 250k/250k [00:00<00:00, 1.61MB/s]\n",
      "\n",
      "\n",
      "100%|██████████| 343k/343k [00:00<00:00, 1.81MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████| 5.03M/5.03M [00:00<00:00, 7.75MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 214M/214M [00:14<00:00, 15.0MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to temporary folder: /Users/oldadministrator/.cache/kagglehub/models/google/speciesnet/PyTorch/v4.0.1a/1\n",
      "6 files copied to: content/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose the folder we're going to download the model to\n",
    "model_path = 'content/models'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# Download the model (it will go to a folder like /kaggle/input/...)\n",
    "download_path = kagglehub.model_download('google/speciesnet/PyTorch/v4.0.1a',\n",
    "                                          force_download=True)\n",
    "\n",
    "print(f'Model downloaded to temporary folder: {download_path}')\n",
    "\n",
    "# List the contents of the downloaded directory to identify the actual files/subdirectories\n",
    "model_files = os.listdir(download_path)\n",
    "\n",
    "# Copy the contents of the model file to our destination folder\n",
    "for item_name in model_files:\n",
    "    source_path = os.path.join(download_path, item_name)\n",
    "    destination_path = os.path.join(model_path, item_name)\n",
    "    if os.path.isfile(source_path):\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "    elif os.path.isdir(source_path):\n",
    "        shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
    "\n",
    "print(f'{len(model_files)} files copied to: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d8ff34a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T22:32:07.997547Z",
     "iopub.status.busy": "2025-05-19T22:32:07.997295Z",
     "iopub.status.idle": "2025-05-19T22:32:42.996088Z",
     "shell.execute_reply": "2025-05-19T22:32:42.995248Z"
    },
    "papermill": {
     "duration": 35.051602,
     "end_time": "2025-05-19T22:32:43.022878",
     "exception": false,
     "start_time": "2025-05-19T22:32:07.971276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "# Pick the model we want to use (4.0.1a)\n",
    "model = SpeciesNet(model_path)\n",
    "\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcb8f823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T22:32:43.074192Z",
     "iopub.status.busy": "2025-05-19T22:32:43.073966Z",
     "iopub.status.idle": "2025-05-19T23:58:00.318899Z",
     "shell.execute_reply": "2025-05-19T23:58:00.318098Z"
    },
    "papermill": {
     "duration": 5117.289495,
     "end_time": "2025-05-19T23:58:00.337834",
     "exception": false,
     "start_time": "2025-05-19T22:32:43.048339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filepath': 'images/batch_1/2024-02-01_Bubbly_spypoint_garden--PICT3482.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19.9 s, sys: 2min 41s, total: 3min 1s\n",
      "Wall time: 27.7 s\n",
      "Predictions:\n",
      "images/batch_1/2024-02-01_Bubbly_spypoint_garden--PICT3482.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_0.json saved to images/batch_0\n",
      "{'filepath': 'images/batch_2/2024-05-25_WM_Boardwalk_D--PICT1409.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19.7 s, sys: 2min 43s, total: 3min 2s\n",
      "Wall time: 25.7 s\n",
      "Predictions:\n",
      "images/batch_2/2024-05-25_WM_Boardwalk_D--PICT1409.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_1.json saved to images/batch_1\n",
      "{'filepath': 'images/batch_3/2024-05-25_WM_Boardwalk_D--PICT1353.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19.6 s, sys: 2min 46s, total: 3min 6s\n",
      "Wall time: 26.7 s\n",
      "Predictions:\n",
      "images/batch_3/2024-05-25_WM_Boardwalk_D--PICT1353.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_2.json saved to images/batch_2\n",
      "{'filepath': 'images/batch_4/2024-02-01_Bubbly_spypoint_garden--PICT3680.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 20 s, sys: 2min 42s, total: 3min 2s\n",
      "Wall time: 26.3 s\n",
      "Predictions:\n",
      "images/batch_4/2024-02-01_Bubbly_spypoint_garden--PICT3680.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_3.json saved to images/batch_3\n",
      "{'filepath': 'images/batch_5/2024-02-01_Bubbly_spypoint_garden--PICT3694.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 21.3 s, sys: 2min 50s, total: 3min 11s\n",
      "Wall time: 27.6 s\n",
      "Predictions:\n",
      "images/batch_5/2024-02-01_Bubbly_spypoint_garden--PICT3694.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_4.json saved to images/batch_4\n",
      "{'filepath': 'images/batch_6/2024-05-25_WM_Boardwalk_D--PICT1233.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19.4 s, sys: 2min 46s, total: 3min 6s\n",
      "Wall time: 26.6 s\n",
      "Predictions:\n",
      "images/batch_6/2024-05-25_WM_Boardwalk_D--PICT1233.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_5.json saved to images/batch_5\n",
      "{'filepath': 'images/batch_7/2024-05-25_WM_Boardwalk_D--PICT1179.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19.3 s, sys: 2min 40s, total: 2min 59s\n",
      "Wall time: 26.2 s\n",
      "Predictions:\n",
      "images/batch_7/2024-05-25_WM_Boardwalk_D--PICT1179.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_6.json saved to images/batch_6\n",
      "{'filepath': 'images/batch_8/2024-02-01_Bubbly_spypoint_garden--PICT3864.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 19 s, sys: 2min 44s, total: 3min 3s\n",
      "Wall time: 25.9 s\n",
      "Predictions:\n",
      "images/batch_8/2024-02-01_Bubbly_spypoint_garden--PICT3864.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_7.json saved to images/batch_7\n",
      "{'filepath': 'images/batch_9/2024-02-01_Bubbly_spypoint_garden--PICT4110.JPG', 'latitude': 41.906782, 'longitude': -87.651927}\n",
      "CPU times: user 1min, sys: 8min 47s, total: 9min 48s\n",
      "Wall time: 1min 22s\n",
      "Predictions:\n",
      "images/batch_9/2024-02-01_Bubbly_spypoint_garden--PICT4110.JPG => f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n",
      "predictions_dict_8.json saved to images/batch_8\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/batch_10'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instances\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(os.listdir(images_root))):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     instances = \u001b[43mcreate_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimages_root\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/batch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_index\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# make the predictions and get a sense of how long it would take\u001b[39;00m\n\u001b[32m     23\u001b[39m     get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpredictions_dict = model.predict(instances_dict=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstances\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: instances})\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcreate_instances\u001b[39m\u001b[34m(batch_folder)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_instances\u001b[39m(batch_folder):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     image_paths = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_folder\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f.lower().endswith(\u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      5\u001b[39m     instances = []\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'images/batch_10'"
     ]
    }
   ],
   "source": [
    "# Let's format a request string as a list of dicts (aka JSON string format)\n",
    "def create_instances(batch_folder):\n",
    "    image_paths = [f'{batch_folder}/{f}' for f in os.listdir(batch_folder) if f.lower().endswith('.jpg')]\n",
    "\n",
    "    instances = []\n",
    "    for image_path in image_paths:\n",
    "        instances.append({\n",
    "            'filepath': image_path,\n",
    "            'latitude': 41.906782,\n",
    "            'longitude': -87.651927\n",
    "        })\n",
    "\n",
    "    # Check that it's saved correctly by verifying the first\n",
    "    print(instances[0])\n",
    "\n",
    "    return instances\n",
    "\n",
    "\n",
    "for batch_index in range(len(os.listdir(images_root))):\n",
    "    instances = create_instances(f'{images_root}/batch_{batch_index+1}')\n",
    "\n",
    "    # make the predictions and get a sense of how long it would take\n",
    "    %time predictions_dict = model.predict(instances_dict={\"instances\": instances})\n",
    "\n",
    "    print_predictions(predictions_dict) # show the first prediction of each batch\n",
    "\n",
    "    # Save the dict to the batch folder\n",
    "    with open(f'{images_root}/batch_{batch_index}/predictions_dict_{batch_index}.json', 'w') as f:\n",
    "        json.dump(predictions_dict, f, indent=2)\n",
    "\n",
    "    print(f'predictions_dict_{batch_index}.json saved to {images_root}/batch_{batch_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "780d9cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:00.390994Z",
     "iopub.status.busy": "2025-05-19T23:58:00.390748Z",
     "iopub.status.idle": "2025-05-19T23:58:04.179763Z",
     "shell.execute_reply": "2025-05-19T23:58:04.178983Z"
    },
    "papermill": {
     "duration": 3.816943,
     "end_time": "2025-05-19T23:58:04.180961",
     "exception": false,
     "start_time": "2025-05-19T23:58:00.364018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 1444 predictions into output/predictions_dict_master.json\n"
     ]
    }
   ],
   "source": [
    "# To concatenate all the json files\n",
    "output_file = output_root / \"predictions_dict_master.json\"\n",
    "\n",
    "# Initialize the master predictions list\n",
    "master_predictions = []\n",
    "\n",
    "# Loop through files matching the pattern\n",
    "for json_file in sorted(images_root.glob(\"batch_*/predictions_dict_*.json\")):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        if \"predictions\" in data:\n",
    "            master_predictions.extend(data[\"predictions\"])  # Concatenate predictions!\n",
    "        else:\n",
    "            print(f\"{json_file} missing 'predictions' key\")\n",
    "\n",
    "# Write the combined predictions to a new file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump({\"predictions\": master_predictions}, f, indent=2)\n",
    "\n",
    "print(f\"Combined {len(master_predictions)} predictions into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda4fd9",
   "metadata": {
    "papermill": {
     "duration": 0.02625,
     "end_time": "2025-05-19T23:58:04.233987",
     "exception": false,
     "start_time": "2025-05-19T23:58:04.207737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's save the predictions dict json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb55eb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:04.286992Z",
     "iopub.status.busy": "2025-05-19T23:58:04.286484Z",
     "iopub.status.idle": "2025-05-19T23:58:49.527249Z",
     "shell.execute_reply": "2025-05-19T23:58:49.526528Z"
    },
    "papermill": {
     "duration": 45.268645,
     "end_time": "2025-05-19T23:58:49.528615",
     "exception": false,
     "start_time": "2025-05-19T23:58:04.259970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from output/predictions_dict_master.json\n",
      "This appears to be a SpeciesNet output file, converting to MD format\n",
      "Writing temporary results to /var/folders/kw/7t07x0j577n5mp3fbbf1q4lh0000gq/T/megadetector_temp_files/7c13e294-3905-11f0-81e5-fa4f0e7b467b.json\n",
      "Converting results to dataframe\n",
      "Finished loading MegaDetector results for 1444 images from output/predictions_dict_master.json\n",
      "Assigning images to rendering categories\n",
      "100%|████████████████████████████████████| 1444/1444 [00:00<00:00, 76902.05it/s]\n",
      "Finished loading and preprocessing 1444 rows from detector output, predicted 42 positives.\n",
      "100%|██████████████████████████████████████| 1444/1444 [00:09<00:00, 150.58it/s]\n",
      "Rendered 1444 images (of 1444) in 9.59 seconds (0.01 seconds per image)\n",
      "Generating classification category report\n",
      "This appears to be a SpeciesNet output file, converting to MD format\n",
      "Writing temporary results to /var/folders/kw/7t07x0j577n5mp3fbbf1q4lh0000gq/T/megadetector_temp_files/81e2aa84-3905-11f0-81e5-fa4f0e7b467b.json\n",
      "Finished writing html to working/output/docs/index.html\n"
     ]
    }
   ],
   "source": [
    "# Create a docs folder for previewing the images\n",
    "output_path = 'working/output/docs'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# change n to sample to -1 for all\n",
    "!python -m megadetector.postprocessing.postprocess_batch_results output/predictions_dict_master.json working/output/docs --num_images_to_sample 2000 --confidence_threshold 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0c73f",
   "metadata": {
    "papermill": {
     "duration": 0.10003,
     "end_time": "2025-05-19T23:58:49.667557",
     "exception": false,
     "start_time": "2025-05-19T23:58:49.567527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's zip the folder so we can easily download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9a0f4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:49.741937Z",
     "iopub.status.busy": "2025-05-19T23:58:49.741278Z",
     "iopub.status.idle": "2025-05-19T23:58:54.361315Z",
     "shell.execute_reply": "2025-05-19T23:58:54.360753Z"
    },
    "papermill": {
     "duration": 4.658995,
     "end_time": "2025-05-19T23:58:54.362654",
     "exception": false,
     "start_time": "2025-05-19T23:58:49.703659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('working/output/docs', 'zip', 'working/output/docs')\n",
    "\n",
    "# and finally clean up the tree that made it this far\n",
    "shutil.rmtree('working/output/docs')  # Deletes the folder\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelId": 247762,
     "modelInstanceId": 291118,
     "sourceId": 348614,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16567.706438,
   "end_time": "2025-05-19T23:58:57.230588",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-19T19:22:49.524150",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
